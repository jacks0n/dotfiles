# vim: filetype=sh

# Helper function to check if a command exists.
command_exists() {
  type "$1" &>/dev/null
}

# ag / The Silver Searcher shortcuts.
# https://github.com/ggreer/the_silver_searcher.
a() { ag "$1" "${2:-.}"; }
au() { ag -u "$1" "${2:-.}"; }
al() { ag -l "$1" "${2:-.}"; }
ae() {
  ag --hidden --nobreak --nonumbers --noheading "${2:-.}" |
    fzf --ansi --select-1 --query="$1" --extended --multi |
    while read -r grep_line; do
      filepath="$(echo "$grep_line" | cut -d ':' -f 1)"
      linenum="$(echo "$grep_line" | cut -d ':' -f 2)"
      $EDITOR "${filepath}:${linenum}" 2>/dev/null
    done
}

# find shortcuts, matches highlighted inline.
# Wildcard find, matching *<keyword>*
f() {
  sudo find "${2:-.}" -iname "*$1*" 2>/dev/null
}

##
# Find the largest file in a given directory.
# Arguments:
# 1. Directory path to search.
# 2. Depth to search the provided directory.
##
find-largest-file() {
  find "$1" -maxdepth "${2:-9999}" -type f -printf '%s %p\n' 2>/dev/null | sort -nr | sed 's/^[[:digit:]]* //g' | head -n "${3:-500}"
}

random-joke() {
  "$HOME/.dotfiles/bin/joke.py"
}

# Random joke, with random rainbow coloured ASCII art.
cowjoke() {
  if command_exists cowsay && command_exists random-joke && command_exists lolcrab; then
    local COWSAY_FILE="$(cowsay -l | tail -n +2 | tr ' ' '\n' | grep -v '^$' | shuf -n1)"
    random-joke | cowsay -f "$COWSAY_FILE" | lolcrab
  fi
}

# Recursively change ownerwhip of the path to $USER.
chownme() {
  sudo chown -R "${USER}:staff" "$@"
}

# cd to a previously visited directory matching FUZZY_PATTERN
unalias z 2>/dev/null
z() {
  if [[ -z "$*" ]]; then
    cd "$(_z -l 2>&1 | fzf +s --tac | sed 's/^[0-9,.]* *//')"
  else
    _last_z_args="$@"
    _z "$@"
  fi
}

git_maintain() {
  # Remove dangling commits/blobs.
  git reflog expire --expire=now --all

  # Verify connectivity and validity of the DB objects.
  git fsck --full --unreachable

  # Cleanup unused branches.
  git remote | xargs --no-run-if-empty git remote prune

  # Re-pack repository objects.
  # @see https://gcc.gnu.org/ml/gcc/2007-12/msg00165.html
  git repack -a -d --depth=250 --window=250

  # Garbage collection.
  git gc --prune=now
}

groot() {
  cd "$(git rev-parse --show-toplevel)"
}

# Add colours to man pages.
man() {
  env LESS_TERMCAP_mb=$'\E[01;31m' \
    LESS_TERMCAP_md=$'\E[01;38;5;74m' \
    LESS_TERMCAP_me=$'\E[0m' \
    LESS_TERMCAP_se=$'\E[0m' \
    LESS_TERMCAP_so=$'\E[38;5;246m' \
    LESS_TERMCAP_ue=$'\E[0m' \
    LESS_TERMCAP_us=$'\E[04;38;5;146m' \
    man $@
}

# Reload shell - Zsh or Bash.
# Sources ~/.zshrc or ~/.profile by default. If the `--new` argument is given,
# the current shell will be re-launched, disregarding any environment changes.
reload() {
  # Get current shell process name. Compatible with BSD and GNU `ps`.
  ME="$(ps -p $$ -o 'comm=')" # zsh and bash usually prefixed with '-'

  # `--new` specified. Lose changes, start new shell.
  if [[ $1 == '--new' ]]; then
    [[ $ME == *zsh ]] && exec zsh -li
    [[ $ME == *bash ]] && exec bash -li
  else
    [[ $ME == *zsh ]] && source ~/.zshrc
    [[ $ME == *bash ]] && source ~/.bashrc # Assumes it sources .bash_profile
  fi
}

# Clear scrollback buffer - works in plain terminal and zellij.
clear-scrollback() {
  [[ -n "$ZELLIJ" ]] && zellij action clear-screen
  printf '\033[2J\033[3J\033[H'
}

# Print the public key at ~/.ssh/id_rsa.pub, and copy to the clipboard.
pubkey() {
  if [ -f "$HOME/.ssh/id_rsa.pub" ]; then
    echo '=> Public key copied to clipboard.'
    tee >(pbcopy) <"$HOME/.ssh/id_rsa.pub"
  else
    echo '=> ERROR: `~/.ssh/id_rsa.pub` is missing'
  fi
}

# Lists file & directory sizes (defaults to current path), sorted by size.
dl() {
  du --human-readable --total --max-depth=1 "${1:-.}" | sort --human-numeric-sort --reverse
}

# Get the public IP address from OpenDNS, print it and copy to clipboard.
ip() {
  local IP="$(dig +short myip.opendns.com @resolver1.opendns.com)"
  [ $? -ne 0 ] && return # dig will print the error to stderr.
  echo "$IP" | pbcopy
  echo "=> Public IP: $IP copied to clipboard"
}

# Create directory and `cd` into it.
mkcd() {
  [[ $1 == '' ]] && echo 'ERROR: No directory argument supplied.' && return 1
  mkdir -p "$1" && cd "$1" || exit 1
}

# Get the local IPv4 addres(sses) from ifconfig, and copy to clipboard.
localip() {
  local IPS="$(ifconfig | grep 'inet' | cut -d' ' -f2 | grep -v -e '127.0.0.1' -e '::1')"
  [[ "$IPS" == '' ]] && echo '=> No local IP addresses found'

  # Print all if multiple found.
  if [ "$(echo "$IPS" | wc -l)" -ne 1 ]; then
    echo -e "=> Multiple IP addresses found:\n$IPS"
  fi

  echo "$IPS" | pbcopy
  echo "=> IP address $IPS copied to clipboard"
}

# Checks if a website is down with downforeveryoneorjustme.com (URL or raw domain).
isdown() {
  # Strip scheme first.
  local URL="$(echo "$1" | sed 's/http\(s\|\):\/\///g')"
  curl -s "http://www.downforeveryoneorjustme.com/$URL" |
    grep 'just you' |
    php -r 'echo html_entity_decode(trim(strip_tags(fgets(STDIN))));'
  echo
}

# Kill all the tabs in Chrome to free up memory.
chromekill() {
  pgrep '[C]hrome Helper --type=renderer' | grep -v extension-process | tr -s ' ' | cut -d ' ' -f2 | xargs kill
}

# Show the HTTP headers of a given URL.
httpheaders() {
  # Use a fake user-agent (Safari 8.0, OS X), some sites block cURL.
  local CURL_USER_AGENT='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10) AppleWebKit/600.1.25 (KHTML, like Gecko) Version/8.0 Safari/600.1.25'
  curl --silent --user-agent "$CURL_USER_AGENT" --dump-header - "$1" --output /dev/null
}

# Delete shell history lines containing $1, in $HISTFILE (if set), ~/.zsh_history, ~/.bash_history
rmhist() {
  if [ -z "$1" ]; then
    echo '=> ERROR: No history string argument to delete.' >&2
    return 1
  fi
  local HIST_FILES=(~/.zsh_history ~/.bash_history "$HISTFILE")
  for HIST_FILE in "${HIST_FILES[@]}"; do
    echo HIST_FILE=$HIST_FILE
    if [ -f "$HIST_FILE" ]; then
      local MATCH_COUNT="$(grep "$1" "$HIST_FILE" &>/dev/null | wc -l)"
      LC_ALL=C sed -i "/$1/d" "$HIST_FILE"
      echo "=> Deleted $MATCH_COUNT matches from $HIST_FILE"
    fi
  done
}

# Automatically `cd` into last directory in ranger.
# Based on ranger/doc/examples/bash_automatic_cd.sh
# http://ranger.nongnu.org/.
rangercd() {
  local TEMPFILE="/tmp/ranger-$$-chosendir"
  ranger --choosedir="$TEMPFILE" "${@:-.}"
  test -f "$TEMPFILE" &&
    if [ "$(cat -- "$TEMPFILE")" != "$(echo -n "$(pwd)")" ]; then
      cd -- "$(cat "$TEMPFILE")" || exit 1
    fi
  rm -f -- "$TEMPFILE"
}

# Global and user updates.
update() {
  update-global
  update-user
}

# User wide update.
update-user() {
  # Update Vim plugins + COC.
  if command_exists vim; then
    echo '=> Vim Plug install, update, upgrade, clean.'
    vim +'PlugInstall --sync' +'PlugUpdate --sync' +PlugUpgrade +qall

    echo "\n\n=> Vim COC update."
    vim -c 'CocUpdateSync|q'
  fi

  # Update NeoVim plugins + Mason + Treesitter.
  if command_exists nvim; then
    echo "\n\n=> NVim Plug install, update, upgrade, clean."
    nvim --headless +'PlugInstall --sync' +'PlugUpdate --sync' +PlugUpgrade +UpdateRemotePlugins +quitall

    echo "\n\n=> NVim Treesitter update."
    nvim --headless -c 'lua require("nvim-treesitter.install").update():wait()' -c qall

    echo "\n\n=> NVim Mason update (LSP servers + tools)."
    nvim --headless -c 'lua require("plugins.mason")' -c MasonUpdateAll
  fi

  # Update zinit and packages.
  if command_exists zinit && [[ $(basename "$SHELL") == 'zsh' ]]; then
    echo "\n\n=> Updating zinit and packages."
    zinit self-update --no-pager
    zinit update --all --no-pager
    # Force complete rebuild of cache (equivalent to removing and rebuilding).
    autoload -Uz compinit
    compinit -i -C -d
  fi

  # Update Composer packages.
  if command_exists composer; then
    echo "\n\n=> Updating Composer packages."
    composer global update
  fi

  # Update Go packages.
  if command_exists go; then
    echo "\n\n=> Updating Go packages."
    go get -u all
  fi

  # Update uv global tools.
  if command_exists uv; then
    echo "\n\n=> Updating uv global tools."
    uv tool upgrade --all
  fi

  # Update Rust toolchain and Cargo packages.
  if command_exists rustup; then
    echo "\n\n=> Updating Rust toolchain."
    rustup update
  fi
  if command_exists cargo; then
    echo "\n\n=> Updating Cargo packages."
    # Ensure cargo-update is installed, then update all packages.
    cargo install cargo-update 2>/dev/null
    cargo install-update -a
  fi

  # Update `~/bin` repositories.
  if [ -d "$HOME/bin/" ]; then
    find "$HOME/bin/" -mindepth 1 -maxdepth 1 -type d | while read BIN_DIR; do
      (
        cd "$BIN_DIR"
        if [ -d .git ]; then
          echo "\n=> Updating Git repository in '$(pwd)'."
          git fetch --all
          git pull origin --rebase
        fi
        if [ -f composer.json ]; then
          echo "\n=> Updating Composer packages in '$(pwd)'."
          composer update --quiet
        fi
        if [ -f package.json ]; then
          echo "\n=> Updating npm packages in '$(pwd)'."
          npm update
        fi
      )
    done
  fi

  # Execute the local update function, if it exists.
  if hash _update &>/dev/null; then
    _update
  fi
}

# Global update.
update-global() {
  # Download latest repo from Homebrew, and update all packages.
  if command_exists brew; then
    echo '=> Homebrew cleanup, update, repair and link fixes.'
    (
      brew update
      brew cu --all --cleanup --yes
      brew upgrade
      brew autoremove
      brew cleanup -s --prune=all
      rm -rf "$(brew --cache)"
    )
  fi

  # Update OS X.
  if command_exists softwareupdate; then
    echo "\n\n=> Running OS X Software Update."
    sudo softwareupdate --install --all
  fi

  # Update Gem and Gems.
  if command_exists gem; then
    echo "\n\n=> Updating Ruby Gems."
    gem update --system
    gem update
    gem clean
  fi

  # Update npm and npm packages.
  if command_exists npm; then
    echo "\n\n=> Updating npm and npm packages."
    npm install --global npm@latest
    npm update --global
    for pkg in $(npm outdated -g --parseable --depth=0 | cut -d: -f2); do
      npm install -g "$pkg"
    done
  fi

  echo "\n\n=> Done!"
}


##
# Search and replace file contents and file paths.
#
# Arguments:
# - From: String to search for.
# - To: Replacement string.
# - Dir: Directory to search and replace in.
##
rename-and-replace() {
  local FROM="$(preg-quote "$1")"
  local TO="$(preg-quote "$2")"
  local DIR="${3:-.}"
  replace "$FROM" "$TO" "${DIR:-.}"
  rename "$FROM" "$TO" "${DIR:-.}"
}

##
# Replace the contents of a files.
#
# Arguments:
# - From: String to search for.
# - To: Replacement string.
# - Dir: Directory to search and replace in.
##
replace() {
  local FROM="$(preg-quote "$1")"
  local TO="$(preg-quote "$2")"
  local DIR="${3:-.}"

  if [[ $(git rev-parse --is-inside-work-tree 2>/dev/null) == 'true' ]]; then
    ag --hidden --files-with-matches "$FROM" "$DIR" | while read -r filepath; do
      echo "=> Replaced in file '$filepath'"
      sed -i'' -e "s/$FROM/$TO/g" "$filepath"
    done
  else
    find "$DIR" -type f | while read -r filepath; do
      if grep --quiet "$FROM" "$FILEPATH" 2>/dev/null; then
        echo "=> Replaced in file '$FILEPATH'"
        sed -i'' -e "s/$FROM/$TO/g" "$FILEPATH"
      fi
    done
  fi
}

##
# Rename filenames.
#
# Arguments:
# - From: String to search for.
# - To: Replacement string.
# - Dir: Directory to search and replace in.
#
# @todo Support directory paths.
##
rename() {
  local FROM="$1"
  local TO="$2"
  local DIR="${3:-.}"

  find "$DIR" -type f | while read -r FILEPATH; do
    if grep --quiet --fixed-strings "$FROM" 2>/dev/null; then
      echo "=> Replacing filepath '$FILEPATH'"
      echo dirname "$FILEPATH" \| sed "s/$FROM/$TO/g"
      local TO_DIR="$(dirname "$FILEPATH" | sed "s/$FROM/$TO/g")"
      if [ ! -d "$TO_DIR" ]; then
        mkdir -p "$TO_DIR"
      fi
      mv "$FILEPATH" "${FILEPATH/$FROM/$TO}"
    fi
  done
}

##
# Escape a regex quote.
##
preg-quote() {
  if [ -n "$1" ]; then
    php --run 'echo preg_quote($argv[1], "/");' "$1"
  else
    php --run 'echo preg_quote(file_get_contents("php://stdin", "/"));'
  fi
}

##
# Find the largest files in a directory.
#
# Arguments:
# - Directory to check (defaults to $HOME).
# - Number of results to show (defaults to 100).
find-largest-files() {
  local SEARCH_DIR="${1:-$HOME}"
  local NUM_RESULTS=${2:-100}

  sudo find "$SEARCH_DIR" -type f -exec du -Sh {} + | sort -rh | head -n "$NUM_RESULTS"
}

##
# Remove old Docker images, containers, networks, and volumes.
##
docker-cleanup() {
  # Remove stopped containers.
  docker ps --quiet --all --no-trunc --filter 'status=exited' | xargs --no-run-if-empty docker rm --volumes --force

  # Delete all tagged images more than a month old
  # (will fail to remove images still used).
  docker images --all | grep ' months' | awk '{ print $3 }' | xargs --no-run-if-empty docker rmi --force

  # Delete all 'untagged/dangling' (<none>) images
  # Those are used for Docker caching mechanism.
  docker images --quiet --all --no-trunc --filter 'dangling=true' | xargs --no-run-if-empty docker rmi --force

  # Remove old volumes.
  docker volume ls --quiet --filter 'dangling=true' | xargs --no-run-if-empty docker volume rm --force

  # Remove unused networks (prune safely skips pre-defined and active networks).
  docker network prune --force

  # Remove unused images (not just dangling).
  docker image prune --all --force
}

##
# Remove all Docker images, containers, networks, and volumes.
##
docker-wipe() {
  # Remove all containers.
  docker ps --quiet --all --no-trunc | xargs --no-run-if-empty docker rm --volumes --force

  # Remove all images.
  docker images --quiet --all | xargs --no-run-if-empty docker rmi --force

  # Remove all volumes.
  docker volume ls --quiet | xargs --no-run-if-empty docker volume rm --force

  # Remove all networks.
  docker network ls | grep 'bridge' | cut -d' ' -f1 | xargs --no-run-if-empty docker network rm

  docker system prune --all --force --volumes
}

##
# Fancy diff.
#
# @see https://github.com/mookid/diffr
##
difff() {
  diff -u "$1" "$2" | diffr
}

###
# Git
##

# Git add all.
ga() {
  git add --all "${@:-.}"
}

# Git add all, commit if there are inputs, and push.
gpa() {
  git add --all
  if [[ "$(git status --porcelain)" ]]; then
    if ! gcm "$*"; then
      return $?
    fi
  fi
  gpu
}

# Git adds all, then Git commit, optionally with a message.
gcm() {
  if [[ "$*" == '' ]]; then
    git commit
  else
    git commit --message "$*"
  fi
}

# Git push, and open the pull request URL if there is one.
gpu() {
  local symbolic_ref=$(git symbolic-ref --short HEAD)
  local push_output="$(git push --set-upstream origin "$symbolic_ref" 2>&1)"
  pr_url=$(echo "$push_output" | tee /dev/tty | grep 'https' | sed -e 's/remote: *//g' -e 's/ //g')
  if [[ -n "$pr_url" ]]; then
    open "$pr_url"
  fi
}

# Checkout or create a feature/$input branch.
gcbf() {
  checkout=$(git checkout -b "feature/$*" 2>&1 | tee /dev/tty)
  if [[ "$checkout" == 'fatal: a branch named'*'already exists' ]]; then
    git checkout "feature/$*"
  else
    echo "$checkout"
  fi
}

# Fuzzy find and edit a file in a Git repo.
ge() {
  local GIT_ROOT_DIR="$(git rev-parse --show-toplevel 2>/dev/null)"
  if [ ! -d "$GIT_ROOT_DIR" ]; then
    echo 'ERROR: Not in a Git repo.' >&2
    return 1
  fi

  local SELECTED_FILE="$(git ls-files --full-name | fzf --query="$1" --select-1 --extended --cycle)"
  [ -f "$GIT_ROOT_DIR/$SELECTED_FILE" ] && "$VISUAL" "$GIT_ROOT_DIR/$SELECTED_FILE"
}

# Clone a Git repository, cd into the directory,
# and checkout a branch/tag/commit if specified.
gclone() {
  local REPO="$1"
  local CHECKOUT_ID="$2"
  if [ -z "$REPO" ]; then
    echo '=> ERROR: No repository provided.' >&2
    return 1
  fi

  git clone "$REPO" || {
    echo "=> ERROR: Could not clone '$REPO'." >&2
    return 1
  }
  repo_dir="$(basename "$REPO" | sed 's/\.git$//g')"
  cd "$repo_dir" 2>/dev/null || {
    echo "=> ERROR: Could not 'cd' into '$repo_dir'." >&2
    return 1
  }
  if [ -n "$CHECKOUT_ID" ]; then
    git checkout "$CHECKOUT_ID"
  fi
}

# Get the default Git branch.
git-default-branch() {
  if [[ -n $(git show-ref main 2>/dev/null) ]]; then
    echo 'main'
    return 0
  elif [[ -n $(git show-ref master 2>/dev/null) ]]; then
    echo 'master'
    return 0
  fi

  local default_branch=$(git config init.defaultBranch)
  if [ -n "$default_branch" ]; then
    echo "$default_branch"
    return 0
  fi

  return 1
}

# Git pull the upstream branch and master/main.
gpo() {
  local remote=$(git remote)
  git pull "$remote" "$(git rev-parse --symbolic-full-name --abbrev-ref HEAD)"
  git pull "$remote" "$(git-default-branch)"
}

# Git checkout with fzf.
gch() {
  local tags branches target
  branches=$(
    git --no-pager branch \
      --format="%(if)%(HEAD)%(then)%(else)%(if:equals=HEAD)%(refname:strip=3)%(then)%(else)%1B[0;34;1mbranch%09%1B[m%(refname:short)%(end)%(end)" |
      sed '/^$/d'
  ) || return
  tags=$(
    git --no-pager tag | awk '{print "\x1b[35;1mtag\x1b[m\t" $1}'
  ) || return
  target=$(
    (
      echo "$branches"
      echo "$tags"
    ) |
      fzf --no-hscroll --no-multi -n 2 \
        --ansi --preview="git --no-pager log -150 --pretty=format:%s '..{2}'"
  ) || return
  git checkout $(awk '{print $2}' <<<"$target")
}

# 'git fetch' all repositories in the current directory.
git-refresh-branches() {
  find . -name .git -type d | while read -r GIT_DIR; do
    (
      cd "$(dirname "$GIT_DIR")" || exit
      git fetch --all
    )
  done
}

claude-code-mcp-setup() {
  npx cclsp@latest setup
  claude mcp add todoist --env TODOIST_API_TOKEN="$TODOIST_API_TOKEN" -- npx -y @abhiz123/todoist-mcp-server
  claude mcp add notion \
    --env OPENAPI_MCP_HEADERS="{\"Authorization\": \"Bearer $NOTION_TOKEN\", \"Notion-Version\": \"2022-06-28\" }" \
    -- npx -y @notionhq/notion-mcp-server
  claude mcp add gemini-cli -- npx -y gemini-mcp-tool
  claude mcp add Context7 -- npx -y @upstash/context7-mcp
  if [[ $(pwd) == $HOME ]]; then
    claude mcp add filesystem -- npx -y @modelcontextprotocol/server-filesystem \
      ~/Code \
      ~/Desktop \
      ~/Google\ Drive \
      ~/Library/CloudStorage/GoogleDrive-jackson@jacksonc.com/My\ Drive
  else
    claude mcp add filesystem -- npx -y @modelcontextprotocol/server-filesystem "$(pwd)"
  fi
  claude mcp add fetch -- uvx mcp-server-fetch
  [[ ! -d ~/.mcp ]] && mkdir ~/.mcp
  claude mcp add memory --env MEMORY_FILE_PATH=$HOME/.mcp/memory.claude.json -- npx -y @modelcontextprotocol/server-memory
  claude mcp add git -- uvx mcp-server-git
  claude mcp add ddg-search -- uvx duckduckgo-mcp-server
  claude mcp add postgres -- uv run postgres-mcp --access-mode=unrestricted
  claude mcp add dbhub-postgres -- npx -y @bytebase/dbhub --transport stdio --dsn postgres://user:password@localhost:5432/dbname?sslmode=disable
  claude mcp add google-calendar -- npx -y @cocal/google-calendar-mcp
  claude mcp add gmail -- npx -y @gongrzhe/server-gmail-autoauth-mcp
  claude mcp add google_workspace \
    --env GOOGLE_OAUTH_CLIENT_ID="$GOOGLE_OAUTH_CLIENT_ID" \
    --env GOOGLE_OAUTH_CLIENT_SECRET="$GOOGLE_OAUTH_CLIENT_SECRET" \
    -- uvx workspace-mcp
  claude mcp add leann-server -- leann_mcp
  lean build
  claude mcp add awslabs-aws-documentation-mcp-server \
    -- env FASTMCP_LOG_LEVEL=ERROR \
    -- env AWS_DOCUMENTATION_PARTITION=aws \
    -- uvx awslabs.aws-documentation-mcp-server@latest
  claude mcp add awslabs-aws-api-mcp-server \
    -- uvx awslabs.aws-api-mcp-server@latest
  claude mcp add sequential-thinking -- npx -y @modelcontextprotocol/server-sequential-thinking
  claude mcp add serena -- \
    uvx --from git+https://github.com/oraios/serena serena start-mcp-server \
    --context ide-assistant --project "$(pwd)"
  claude mcp add automem \
    --env AUTOMEM_ENDPOINT=http://127.0.0.1:8001 \
    --env AUTOMEM_API_KEY='' \
    -- npx @verygoodplugins/mcp-automem
  claude mcp add kit-dev \
    --env KIT_USE_CHROMA_CLOUD='false' \
    --env KIT_GITHUB_TOKEN="$GITHUB_API_TOKEN" \
    --env OPENAI_API_KEY="$OPENAI_API_KEY" \
    --env GOOGLE_API_KEY="$GEMINI_API_KEY" \
    -- uvx --from 'cased-kit[all]' kit-dev-mcp
  # For Azure services not Azure DevOps.
  claude mcp add azure \
    -- npx @azure/mcp@latest server start
  claude mcp add azure-devops \
    -- npx -y @azure-devops/mcp REPLACEME
  claude mcp add atlassian-official \
    -- npx -y mcp-remote https://mcp.atlassian.com/v1/sse
  docker pull ghcr.io/sooperset/mcp-atlassian:latest
  claude mcp add atlassian \
    --env CONFLUENCE_URL="$CONFLUENCE_URL" \
    --env CONFLUENCE_USERNAME="$CONFLUENCE_USERNAME" \
    --env CONFLUENCE_API_TOKEN="$CONFLUENCE_API_TOKEN" \
    --env JIRA_URL="$JIRA_URL" \
    --env JIRA_USERNAME="$JIRA_USERNAME" \
    --env JIRA_API_TOKEN="$JIRA_API_TOKEN" \
    -- docker run -i --rm \
    -e CONFLUENCE_URL \
    -e CONFLUENCE_USERNAME \
    -e CONFLUENCE_API_TOKEN \
    -e JIRA_URL \
    -e JIRA_USERNAME \
    -e JIRA_API_TOKEN \
    ghcr.io/sooperset/mcp-atlassian:latest
  claude mcp add playwright-fast -- npx @tontoko/fast-playwright-mcp@latest
  claude mcp add playwright \
    -- npx @playwright/mcp@latest
    --user-data-dir '<path>'
  # Requires admin approval
  claude mcp add ms-365 -- npx -y @softeria/ms-365-mcp-server --org-mode
  claude mcp add coderift -- uv run --directory /Users/jackson/Code/coderift coderift-mcp
  claude mcp add ha-mcp \
      -e HOMEASSISTANT_URL="$HOME_ASSISTANT_URL" \
      -e HOMEASSISTANT_TOKEN="$HOME_ASSISTANT_API_TOKEN" \
      -- uvx ha-mcp
}

claude-copy-settings() {
  [[ ! -d .claude ]] && mkdir .claude
  cp ~/.claude/settings.json .claude/settings.local.json
}

claude-copy-settings-all() {
  local ORIG_DIR="$(pwd)"
  cd ~/Code

  for dir in */; do
    dir="${dir%/}"

    [[ ! -d "$dir" ]] && continue

    echo "Processing $dir..."

    mkdir -p "$dir/.claude"

    cp ~/.claude/settings.json "$dir/.claude/settings.json"

    echo "  âœ“ Copied settings to $dir/.claude/settings.json"
  done

  cd "$ORIG_DIR"
  echo "Done! Copied Claude settings to all directories in ~/Code"
}

# Start Claude Code with zellij pane tracking for auto-focus (via claude-focus plugin)
ccd() {
  claude --dangerously-skip-permissions "$@"
}

alias cwc='claude-whitelist-cmd'
claude-whitelist-cmd() {
  local cmd="$*"

  if [[ -z "$cmd" ]]; then
    echo "Error: Please provide a command to whitelist"
    echo "Usage: claude-whitelist-cmd <command>"
    echo "Examples:"
    echo "  claude-whitelist-cmd npm run dev"
    echo "  claude-whitelist-cmd 'docker compose up'"
    return 1
  fi

  local settings_file="$HOME/.claude/settings.json"
  if [[ ! -f "$settings_file" ]]; then
    echo "Error: Claude settings file not found at $settings_file"
    return 1
  fi

  local permission_entry
  if [[ "$cmd" == mcp__* ]]; then
    permission_entry="$cmd"
  else
    permission_entry="Bash(${cmd}:*)"
  fi
  if jq -e ".permissions.allow | index(\"$permission_entry\")" "$settings_file" > /dev/null 2>&1; then
    echo "Command '$cmd' is already whitelisted"
    return 0
  fi

  local temp_file=$(mktemp)
  if jq ".permissions.allow += [\"$permission_entry\"] | .permissions.allow |= sort" "$settings_file" > "$temp_file"; then
    mv "$temp_file" "$settings_file"
    echo "Successfully added '$cmd' to Claude whitelist as '$permission_entry'"
    return 0
  else
    echo "Error: Failed to update Claude settings file"
    rm -f "$temp_file"
    return 1
  fi

  claude-copy-settings-all
}
